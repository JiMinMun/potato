{
  "port": 9001,

  "server_name": "potato annotator",

  "annotation_task_name": "Health Question Asking Ranking - Hitchcock",

  # Potato will write the annotation file for all annotations to this
  # directory, as well as per-annotator output files and state information
  # necessary to restart annotation.
  "output_annotation_dir": "annotation_output/full/",

  # The output format for the all-annotator data. Allowed formats are:
  # * jsonl
  # * json (same output as jsonl)
  # * csv
  # * tsv
  #
  "output_annotation_format": "jsonl",

  # If annotators are using a codebook, this will be linked at the top to the
  # instance for easy access
  "annotation_codebook_url": "",

  "data_files": [
      "data_files/sample_for_human_eval_dartmouth_formatted.jsonl"
  ],

  "item_properties": {
      "id_key": "id",
      "text_key": "text",
      # "kwargs": ["clinical_convo", "question", "optionA", "optionB", "optionC", "optionD", "correct_answer"]
  },

  #list_as_text is used when the input text is actually a list of texts, usually used for best-worst-scaling
  "list_as_text": {
    "text_list_prefix_type": 'None',
    "horizontal": True,
  },

  "user_config": {

    "allow_all_users": True,

    "users": [  ],
  },

  #defining the ways annotators entering the annotation system
  "login": {
      "type": 'password',    #can be 'password' or 'url_direct'
  },

  #the jumping-to-id function will be disabled if "jumping_to_id_disabled" is True
  "jumping_to_id_disabled": False,

  #the navigation bar will be hidden to the annotators if "hide_navbar" is True
  "hide_navbar": False,

  # define the surveyflow of the system, set up the pages before and after the data annotation page
  "surveyflow": {
    "on": True,
    #"order" : ['pre_annotation', 'prestudy_passed', 'prestudy_failed', 'post_annotation'],
    "order" : ['pre_annotation', 'post_annotation'],
    "pre_annotation": [{"file": 'surveyflow/consent.jsonl', "text": "Instruction and Consent"}],
    # "prestudy_passed": ['surveyflow/prestudy_pass.jsonl'],
    # "prestudy_failed": ['surveyflow/prestudy_fail.jsonl'],
    "post_annotation": [
      {"file": 'surveyflow/experience.jsonl', "text": "Thank you! See you again soon!"}
    ],
    # If set, we will automatically generate testing questions similar to the annotation instances, but explicitly ask the annotator to choose one option
    "testing": [],
  },

    #prestudy test, annotators who fail this test will be disalloed to continue annotation
    # "prestudy": {
    #     "on": False,
    #     "minimum_score": 0.8,
    #     "groundtruth_key": 'whether_match',
    #     "question_key": 'Whether the presented sentences are discussing the same scientific finding',
    #     "answer_mapping": {'Yes': True, 'No': False},
    #     "pass_page": 'surveyflow/prestudy_pass.jsonl',
    #     "fail_page": 'surveyflow/prestudy_fail.jsonl'
    # },


    # turn this on to get assignment when we do actual annotation
    "automatic_assignment": {
      #whether do automatic task assignment for annotators, default False.
      "on": False,
      "output_filename": 'task_assignment.json',
      "sampling_strategy": 'random',
      "labels_per_instance": 3,
      "instance_per_annotator": 10,
      "test_question_per_annotator": 0, # you must set up the test question in surveyflow to use this function
      "users": [  ],
      "allow_multiple_submissions": True,
    },


    # How many seconds do you want the annotators spend on each instance, after
    # that, an alert will be sent per alert_time_each_instance seconds.
    "alert_time_each_instance": 10000000,
    "horizontal_key_bindings": true,

    "annotation_schemes": [
      {
        "annotation_type": "ranking",
        "name": "Q1",
        "description": "Q1. (Required) Rank the suggested follow-up questions in the options above from best to worst.",
        "instruction": "Consider which question you would most likely ask a patient, and which question you would least likely ask a patient.",
        "options": [
            "A", "B", "C", "D", "E", "F", "G"
        ],
        # If true, numbers [1-len(labels)] will be bound to each
        # label. Check box annotations with more than 10 are not supported
        # with this simple keybinding and will need to use the full item
        # specification to bind all labels to keys.
        "sequential_key_binding": True,
        "label_requirement": {"required": True}
      },
      {
        "annotation_type": "text",
        # This name gets used in reporting the annotation results
        "name": "Q2",
        # This text is shown to the user and can be a longer statement
        "description": "Q2. (Optional) If you have any comments or suggestions about the provided context, the options, or your chosen ranking please leave them here.",
        # if you want to use multi-line textbox, turn on the text area and set the desired rows and cols of the textbox
        "textarea": {
          "on": True,
          "rows": 2,
          "cols": 40
        },
      },
    ],

    # The html that changes the visualiztation for your task. Change this file
    # to influence the layout and description of your task. This is not a full
    # HTML page, just the piece that does lays out your task's pieces
    #"html_layout": "templates/examples/fixed_keybinding_layout.html",
    # "html_layout": "templates/layout.html",
    "html_layout": "default",

    # The core UI files for Potato. You should not need to change these normally.
    #
    # Exceptions to this might include:
    # 1) You want to add custom CSS/fonts to style your task
    # 2) Your layout requires additional JS/assets to render
    # 3) You want to support additional keybinding magic
    #
    # if you want to use your own template,
    # please replace the string as a path to the template
    "base_html_template": "default",
    "header_file": "default",

    # This is where the actual HTML files will be generated
    "site_dir": "default",
}
